ğŸš€ NÃ¡vrhy na zrychlenÃ­

1. MasivnÃ­ Paralelizace (Low Hanging Fruit ğŸ)
Co udÄ›lat: ZvÃ½Å¡it N_ENVS v 
train_multicore.py
 z 8 na poÄet logickÃ½ch jader tvÃ©ho CPU mÃ­nus 2 (napÅ™. pokud mÃ¡Å¡ 24 vlÃ¡ken, dej tam 22).
ProÄ: Tvoje CPU jede jen na 35%. KaÅ¾dÃ½ novÃ½ proces pÅ™idÃ¡ dalÅ¡Ã­ch 10 agentÅ¯ sbÃ­rajÃ­cÃ­ch data paralelnÄ›.
OÄekÃ¡vanÃ½ dopad: LineÃ¡rnÃ­ nÃ¡rÅ¯st FPS (pokud mÃ¡Å¡ volnÃ¡ jÃ¡dra). GPU zÃ¡tÄ›Å¾ stoupne.

2. Optimalizace SenzorÅ¯ (Lidar Raycasting) âš¡
Co udÄ›lat: PÅ™epsat vÃ½poÄet Lidaru v Agent.update_sensors pomocÃ­ Numba (@jit).
ProÄ: Python je pomalÃ½ ve smyÄkÃ¡ch. Raycasting pro 32 paprskÅ¯ x 80 agentÅ¯ = 2560 vÃ½poÄtÅ¯ kaÅ¾dÃ½ch pÃ¡r milisekund. V ÄistÃ©m Pythonu/Pymunku to brzdÃ­ worker procesy.
OÄekÃ¡vanÃ½ dopad: ZrychlenÃ­ "kroku" prostÅ™edÃ­ o 2x-5x, coÅ¾ umoÅ¾nÃ­ rychlejÅ¡Ã­ krmenÃ­ GPU.

3. Shared Memory Buffer ğŸ§ 
Co udÄ›lat: MÃ­sto posÃ­lÃ¡nÃ­ observacÃ­ pÅ™es Pipe (coÅ¾ data serializuje/pickluje = pomalÃ©) pouÅ¾Ã­t multiprocessing.shared_memory.
ProÄ: S 80+ agenty posÃ­lÃ¡me tam a zpÄ›t spoustu floats. ZÃ¡pis pÅ™Ã­mo do sdÃ­lenÃ© pamÄ›ti odstranÃ­ reÅ¾ii kopÃ­rovÃ¡nÃ­ dat mezi procesy.
OÄekÃ¡vanÃ½ dopad: SnÃ­Å¾enÃ­ latence mezi 
step()
 a model.learn().
 
4. VektorizovanÃ¡ Fyzika na GPU (The "Endgame" Solution â˜¢ï¸)
Co udÄ›lat: Zahodit Pymunk (CPU) a pÅ™ejÃ­t na JAX (Brax/Mjx) nebo Isaac Gym.
ProÄ: SouÄasnÃ¡ architektura je: CPU poÄÃ­tÃ¡ fyziku -> posÃ­lÃ¡ data -> GPU poÄÃ­tÃ¡ sÃ­Å¥. S JAXem bÄ›Å¾Ã­ fyzika pÅ™Ã­mo na GPU vedle neuronovÃ© sÃ­tÄ›. Data neopustÃ­ grafickou kartu.
OÄekÃ¡vanÃ½ dopad: FPS v Å™Ã¡dech stovek tisÃ­c (100k+). Je to ale kompletnÃ­ pÅ™epsÃ¡nÃ­ core/physics.py a 
env/entropy_env.py
.
