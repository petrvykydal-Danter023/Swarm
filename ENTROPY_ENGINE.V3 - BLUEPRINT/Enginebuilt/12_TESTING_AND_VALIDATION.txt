================================================================================
                    12_TESTING_AND_VALIDATION.txt
                    Testovac√≠ Skripty a Validace
================================================================================

================================================================================
1. TESTOVAC√ç FILOSOFIE
================================================================================

V2 PROBL√âM:
  - Testy byly ad-hoc (test_phase2_env.py, test_wrapper_loading.py...)
  - ≈Ω√°dn√° systematick√° struktura
  - Testy nebyly automatizovan√©

V3 ≈òE≈†EN√ç:
  - Strukturovan√° testovac√≠ pyramida
  - Rychl√© smoke testy pro ka≈æd√Ω modul
  - CI/CD integrace (GitHub Actions)
  - Benchmark testy pro performance regression

================================================================================
2. STRUKTURA TEST≈Æ
================================================================================

```
tests/
‚îú‚îÄ‚îÄ unit/                        # Rychl√©, izolovan√© testy
‚îÇ   ‚îú‚îÄ‚îÄ test_physics.py
‚îÇ   ‚îú‚îÄ‚îÄ test_ecs.py
‚îÇ   ‚îú‚îÄ‚îÄ test_communication.py
‚îÇ   ‚îî‚îÄ‚îÄ test_reward.py
‚îÇ
‚îú‚îÄ‚îÄ integration/                 # Testy spolupr√°ce modul≈Ø
‚îÇ   ‚îú‚îÄ‚îÄ test_env_step.py
‚îÇ   ‚îú‚îÄ‚îÄ test_training_loop.py
‚îÇ   ‚îî‚îÄ‚îÄ test_render_integration.py
‚îÇ
‚îú‚îÄ‚îÄ smoke/                       # Rychl√© "funguje v≈Øbec?" testy
‚îÇ   ‚îú‚îÄ‚îÄ smoke_physics.py         # 5 sekund
‚îÇ   ‚îú‚îÄ‚îÄ smoke_brain.py           # 5 sekund
‚îÇ   ‚îú‚îÄ‚îÄ smoke_render.py          # 5 sekund
‚îÇ   ‚îî‚îÄ‚îÄ smoke_full.py            # 30 sekund (cel√Ω pipeline)
‚îÇ
‚îú‚îÄ‚îÄ benchmark/                   # Performance testy
‚îÇ   ‚îú‚îÄ‚îÄ bench_physics_scaling.py # 10/100/1000/10000 agent≈Ø
‚îÇ   ‚îú‚îÄ‚îÄ bench_communication.py
‚îÇ   ‚îî‚îÄ‚îÄ bench_render_fps.py
‚îÇ
‚îî‚îÄ‚îÄ validation/                  # End-to-end validace
    ‚îú‚îÄ‚îÄ validate_navigation.py
    ‚îú‚îÄ‚îÄ validate_communication_grounding.py
    ‚îî‚îÄ‚îÄ validate_formation.py
```

================================================================================
3. UNIT TESTY
================================================================================

3.1 PHYSICS TESTS
-----------------
```python
# tests/unit/test_physics.py

import pytest
import jax.numpy as jnp
from entropy.core.physics import physics_step, compute_lidars
from entropy.core.world import WorldState, create_empty_world

class TestPhysicsStep:
    def test_agent_moves_forward(self):
        """Agent s akci 'vp≈ôed' se pohne ve smƒõru sv√©ho √∫hlu."""
        state = create_empty_world(num_agents=1)
        state = state.replace(
            agent_positions=jnp.array([[100.0, 100.0]]),
            agent_angles=jnp.array([0.0])  # Smƒõr: vpravo
        )
        
        actions = jnp.array([[1.0, 1.0]])  # Oba motory vp≈ôed
        new_state = physics_step(state, actions, dt=0.1)
        
        # Agent se pohnul vpravo
        assert new_state.agent_positions[0, 0] > 100.0
        
    def test_agent_rotates(self):
        """Rozd√≠ln√© motory zp≈Øsob√≠ rotaci."""
        state = create_empty_world(num_agents=1)
        actions = jnp.array([[1.0, -1.0]])  # Lev√Ω vp≈ôed, prav√Ω vzad = rotace
        new_state = physics_step(state, actions, dt=0.1)
        
        assert new_state.agent_angles[0] != 0.0
        
    def test_wall_collision(self):
        """Agent neprolet√≠ zd√≠."""
        state = create_empty_world(num_agents=1)
        state = state.replace(
            agent_positions=jnp.array([[10.0, 10.0]]),  # Bl√≠zko okraje
            wall_segments=jnp.array([[0.0, 0.0, 0.0, 100.0]])  # Lev√° zeƒè
        )
        
        actions = jnp.array([[-1.0, -1.0]])  # Jeƒè doleva (do zdi)
        new_state = physics_step(state, actions, dt=0.1)
        
        # Agent se nepohnul za zeƒè
        assert new_state.agent_positions[0, 0] >= 10.0  # Radius


class TestLidar:
    def test_lidar_detects_wall(self):
        """Lidar detekuje bl√≠zkou zeƒè."""
        state = create_empty_world(num_agents=1)
        state = state.replace(
            agent_positions=jnp.array([[50.0, 50.0]]),
            wall_segments=jnp.array([[100.0, 0.0, 100.0, 100.0]])  # Zeƒè vpravo
        )
        
        readings = compute_lidars(state, num_rays=32, max_range=300.0)
        
        # Paprsek smƒõ≈ôuj√≠c√≠ vpravo (index ~8 pro 32 paprsk≈Ø) vid√≠ zeƒè
        # readings[0, 8] by mƒõla b√Ωt men≈°√≠ ne≈æ 1.0 (ne max range)
        assert readings[0, 8] < 1.0
```

3.2 ECS TESTS
-------------
```python
# tests/unit/test_ecs.py

from entropy.core.ecs import EntityRegistry, create_agent, create_goal
from entropy.components import TransformComponent, PhysicsComponent

class TestECSRegistry:
    def test_create_entity(self):
        registry = EntityRegistry()
        eid = registry.create_entity()
        assert eid == 0
        assert eid in registry.active_entities
        
    def test_add_component(self):
        registry = EntityRegistry()
        eid = registry.create_entity()
        
        registry.add_component(eid, TransformComponent(position=[0, 0], angle=0))
        
        comp = registry.get_component(eid, TransformComponent)
        assert comp is not None
        assert comp.position == [0, 0]
        
    def test_entity_factory(self):
        registry = EntityRegistry()
        agent_id = create_agent(registry, position=(100, 100))
        
        # Agent m√° v≈°echny pot≈ôebn√© komponenty
        assert registry.get_component(agent_id, TransformComponent) is not None
        assert registry.get_component(agent_id, PhysicsComponent) is not None
```

3.3 COMMUNICATION TESTS
-----------------------
```python
# tests/unit/test_communication.py

from entropy.brain.communication import CommunicationEncoder, encode_message, decode_messages

class TestCommunication:
    def test_encode_decode_roundtrip(self):
        """Zak√≥dovan√° zpr√°va se spr√°vnƒõ dek√≥duje."""
        token = 7  # FOUND_TARGET
        payload = jnp.array([0.5, 0.3, 0.8, 0.0])
        
        message = encode_message(token, payload)
        decoded_token, decoded_payload = decode_message(message)
        
        assert decoded_token == token
        assert jnp.allclose(decoded_payload, payload, atol=0.01)
        
    def test_message_shape(self):
        """Zpr√°va m√° spr√°vn√Ω tvar."""
        # Canonical obs_dim = 32 + 2 + 2 + 64 = 100 (see 00_OVERVIEW.txt)
        encoder = CommunicationEncoder(obs_dim=100, vocab_size=32, payload_dim=4)
        obs = jnp.zeros(36)
        
        message = encoder(obs)
        
        assert message.shape == (36,)  # 32 tokens + 4 payload
```

================================================================================
4. SMOKE TESTY (Rychl√° validace)
================================================================================

```python
# tests/smoke/smoke_physics.py
"""
Rychl√Ω test fyziky. Spust√≠ se za <5 sekund.
Pou≈æit√≠: python -m pytest tests/smoke/smoke_physics.py -v
"""

import jax
from entropy.core.world import create_random_world
from entropy.core.physics import physics_step

def test_smoke_physics():
    """Fyzika se v≈Øbec spust√≠ a nepadne."""
    print("üî• Smoke Test: Physics")
    
    # 1. Vytvo≈ô svƒõt
    rng = jax.random.PRNGKey(42)
    state = create_random_world(rng, num_agents=10)
    print(f"  ‚úÖ World created: {state.num_agents} agents")
    
    # 2. Proveƒè 100 krok≈Ø
    for i in range(100):
        actions = jax.random.uniform(rng, shape=(10, 2), minval=-1, maxval=1)
        state = physics_step(state, actions)
    print(f"  ‚úÖ 100 steps completed")
    
    # 3. Zkontroluj ≈æe nic nen√≠ NaN
    assert not jnp.any(jnp.isnan(state.agent_positions)), "NaN in positions!"
    assert not jnp.any(jnp.isnan(state.agent_velocities)), "NaN in velocities!"
    print(f"  ‚úÖ No NaN values")
    
    print("üéâ Smoke Test PASSED!")
```

```python
# tests/smoke/smoke_brain.py

def test_smoke_brain():
    """Brain inference funguje."""
    print("üî• Smoke Test: Brain")
    
    # 1. Vytvo≈ô brain
    from entropy.brain import BrainManager, PPOPolicy
    manager = BrainManager()
    policy = PPOPolicy(obs_dim=100, action_dim=2)
    print(f"  ‚úÖ Policy created")
    
    # 2. Inference
    obs = jnp.zeros((10, 100))  # 10 agent≈Ø
    actions = policy.act(obs)
    print(f"  ‚úÖ Inference: {actions.shape}")
    
    assert actions.shape == (10, 2)
    print("üéâ Smoke Test PASSED!")
```

```python
# tests/smoke/smoke_full.py

def test_smoke_full_pipeline():
    """Cel√Ω pipeline: env -> brain -> step -> reward."""
    print("üî• Smoke Test: Full Pipeline")
    
    from entropy import create_env, create_policy
    
    # 1. Env
    env = create_env(num_agents=5)
    state = env.reset()
    print(f"  ‚úÖ Env reset")
    
    # 2. Policy
    policy = create_policy(env.observation_space, env.action_space)
    print(f"  ‚úÖ Policy created")
    
    # 3. Rollout
    total_reward = 0
    for _ in range(100):
        obs = env.get_observations(state)
        actions = policy.act(obs)
        state, rewards, dones, infos = env.step(state, actions)
        total_reward += rewards.sum()
    print(f"  ‚úÖ 100 steps, total reward: {total_reward:.2f}")
    
    print("üéâ Smoke Test PASSED!")
```

================================================================================
5. BENCHMARK TESTY
================================================================================

```python
# tests/benchmark/bench_physics_scaling.py
"""
Mƒõ≈ô√≠ FPS pro r≈Øzn√Ω poƒçet agent≈Ø.
V√Ωstup: Tabulka a graf pro performance regression.
"""

import time
import jax
from entropy.core.world import create_random_world
from entropy.core.physics import physics_step

def benchmark_physics(num_agents, num_steps=1000):
    rng = jax.random.PRNGKey(42)
    state = create_random_world(rng, num_agents=num_agents)
    actions = jax.random.uniform(rng, shape=(num_agents, 2), minval=-1, maxval=1)
    
    # Warmup (JIT compile)
    for _ in range(10):
        state = physics_step(state, actions)
    
    # Benchmark
    start = time.perf_counter()
    for _ in range(num_steps):
        state = physics_step(state, actions)
    elapsed = time.perf_counter() - start
    
    fps = num_steps / elapsed
    return fps

def test_benchmark_scaling():
    results = []
    for n in [10, 100, 1000, 10000]:
        fps = benchmark_physics(n)
        results.append((n, fps))
        print(f"  {n:>6} agents: {fps:>10.0f} FPS")
    
    # Validace: mus√≠me splnit minim√°ln√≠ po≈æadavky
    assert results[0][1] > 100000, "10 agents should be >100k FPS"
    assert results[1][1] > 10000, "100 agents should be >10k FPS"
    assert results[2][1] > 1000, "1000 agents should be >1k FPS"
```

================================================================================
6. VALIDAƒåN√ç TESTY (End-to-End)
================================================================================

```python
# tests/validation/validate_navigation.py
"""
Ovƒõ≈ô√≠, ≈æe natr√©novan√Ω agent um√≠ navigovat k c√≠li.
Pou≈æ√≠v√° se po tr√©ninku pro sanity check.
"""

def test_navigation_after_training():
    """Natr√©novan√Ω agent dos√°hne c√≠le v 90% p≈ô√≠pad≈Ø."""
    
    from entropy import create_env, load_policy
    
    env = create_env(num_agents=1, difficulty="easy")
    policy = load_policy("models/navigation_latest.pt")
    
    successes = 0
    num_episodes = 100
    
    for ep in range(num_episodes):
        state = env.reset()
        for step in range(500):
            obs = env.get_observations(state)
            actions = policy.act(obs, deterministic=True)
            state, rewards, dones, _ = env.step(state, actions)
            if dones[0]:
                if state.goal_reached[0]:
                    successes += 1
                break
    
    success_rate = successes / num_episodes
    print(f"Success rate: {success_rate:.1%}")
    
    assert success_rate > 0.9, f"Expected >90% success, got {success_rate:.1%}"
```

```python
# tests/validation/validate_communication_grounding.py
"""
Ovƒõ≈ô√≠, ≈æe komunikace je grounded (slova odpov√≠daj√≠ situac√≠m).
"""

def test_communication_grounding():
    """Token FOUND_TARGET se vys√≠l√° jen kdy≈æ agent vid√≠ c√≠l."""
    
    from entropy import create_env, load_policy
    
    env = create_env(num_agents=5)
    policy = load_policy("models/communication_latest.pt")
    
    correct_predictions = 0
    total_non_silence = 0
    
    state = env.reset()
    for _ in range(1000):
        obs = env.get_observations(state)
        actions = policy.act(obs)
        
        for i in range(5):
            token = jnp.argmax(state.agent_messages[i][:32])
            if token != 0:  # Ne-silence
                total_non_silence += 1
                
                if token == 7:  # FOUND_TARGET
                    # Agent by mƒõl vidƒõt sv≈Øj c√≠l
                    can_see = can_see_goal(state, i)
                    if can_see:
                        correct_predictions += 1
                        
        state, _, _, _ = env.step(state, actions)
    
    grounding_accuracy = correct_predictions / max(total_non_silence, 1)
    print(f"Grounding accuracy: {grounding_accuracy:.1%}")
    
    assert grounding_accuracy > 0.8, "Communication should be >80% grounded"
```

================================================================================
7. CLI PRO TESTY
================================================================================

```bash
# Spustit v≈°echny unit testy
pytest tests/unit/ -v

# Spustit smoke testy (rychl√° validace)
pytest tests/smoke/ -v --timeout=30

# Spustit benchmarky
pytest tests/benchmark/ -v --benchmark

# Spustit validaci po tr√©ninku
pytest tests/validation/ -v

# Spustit v≈°e
pytest tests/ -v

# Coverage report
pytest tests/ --cov=entropy --cov-report=html
```

================================================================================
8. CI/CD INTEGRACE (GitHub Actions)
================================================================================

```yaml
# .github/workflows/test.yml

name: Tests

on: [push, pull_request]

jobs:
  smoke:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - run: pip install -r requirements.txt
      - run: pytest tests/smoke/ -v --timeout=60

  unit:
    runs-on: ubuntu-latest
    needs: smoke  # Smoke mus√≠ proj√≠t prvn√≠
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
      - run: pip install -r requirements.txt
      - run: pytest tests/unit/ -v --cov=entropy

  benchmark:
    runs-on: ubuntu-latest
    needs: unit
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
      - run: pip install -r requirements.txt
      - run: pytest tests/benchmark/ -v
      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: benchmark_results.json
```

================================================================================
9. TESTOVAC√ç FIXTURES
================================================================================

```python
# tests/conftest.py (pytest fixtures)

import pytest
import jax

@pytest.fixture
def rng():
    """Reprodukovateln√Ω RNG pro testy."""
    return jax.random.PRNGKey(42)

@pytest.fixture
def small_world(rng):
    """Mal√Ω svƒõt pro rychl√© testy."""
    from entropy.core.world import create_random_world
    return create_random_world(rng, num_agents=5, arena_size=(200, 200))

@pytest.fixture
def trained_policy():
    """P≈ôedtr√©novan√° policy pro validaƒçn√≠ testy."""
    from entropy.brain import load_policy
    return load_policy("test_fixtures/dummy_policy.pt")

@pytest.fixture
def mock_brain_manager(tmp_path):
    """BrainManager s doƒçasn√Ωm √∫lo≈æi≈°tƒõm."""
    from entropy.brain import BrainManager
    return BrainManager(storage_dir=str(tmp_path))
```

================================================================================
                            KONEC TESTING
           Pokraƒçuj ƒçten√≠m 13_SWARM_AI_FACTORY.txt pro automatizovan√Ω tr√©nink.
================================================================================
