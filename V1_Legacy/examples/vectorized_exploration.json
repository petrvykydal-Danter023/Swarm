{
    "task_name": "vectorized_exploration",
    "world_width": 100.0,
    "world_height": 100.0,
    "env_params": {
        "num_agents": 50,
        "dt": 0.1,
        "friction": 0.15,
        "goal_type": "static",
        "agent_mode": "search",
        "detection_radius": 25.0,
        "enable_communication": true,
        "comm_range": 30.0,
        "packet_loss_prob": 0.1,
        "reward_type": "vectorized",
        "special_objects": [
            {
                "type": "goal",
                "x": 85,
                "y": 85,
                "radius": 8
            }
        ],
        "sensors": [
            "position",
            "velocity",
            "goal_vector",
            "neighbor_vectors",
            "neighbor_signals",
            "energy"
        ]
    },
    "training_params": {
        "algo": "PPO",
        "total_timesteps": 300000,
        "learning_rate": 0.0003,
        "max_episode_steps": 400,
        "n_envs": 4,
        "normalize": true,
        "save_model_path": "models/saved/vectorized_exploration"
    }
}