{
    "task_name": "bridge_building",
    "description": "Swarm agents form a human bridge across a gap",
    "observation_type": "spatial",
    "action_space_type": "discrete",
    "env_params": {
        "world_width": 100,
        "world_height": 50,
        "num_agents": 15,
        "physics": {
            "gravity_y": 2.0,
            "friction": 0.3,
            "time_step": 0.1
        },
        "special_objects": [
            {
                "type": "gap",
                "x1": 40,
                "x2": 60,
                "y": 25
            },
            {
                "type": "goal",
                "x": 90,
                "y": 25
            }
        ]
    },
    "reward_code": "# Bridge building reward\n# Agents need to form a chain across the gap\n\nreward = 0.0\ngap = None\nfor obj in env_state.get('gaps', []):\n    gap = obj\n    break\n\nif gap:\n    gap_x1, gap_x2 = gap['x1'], gap['x2']\n    gap_y = gap['y']\n    gap_center_x = (gap_x1 + gap_x2) / 2\n    \n    # Check if agent is in the gap zone (horizontally)\n    in_gap_zone = gap_x1 <= agent['x'] <= gap_x2\n    \n    if in_gap_zone:\n        # Reward for being at the right height (near gap level)\n        height_diff = abs(agent['y'] - gap_y)\n        if height_diff < 5:\n            reward += 2.0\n        \n        # Bonus for grabbing (forming chain)\n        if agent['is_grabbing']:\n            reward += 1.0\n            \n            # Extra bonus if grabbing near other agents\n            for neighbor in env_state['neighbors']:\n                if neighbor['is_grabbing']:\n                    dist = math.sqrt((agent['x']-neighbor['x'])**2 + (agent['y']-neighbor['y'])**2)\n                    if dist < 5:\n                        reward += 3.0\n    else:\n        # Encourage movement toward gap\n        dist_to_gap = min(abs(agent['x'] - gap_x1), abs(agent['x'] - gap_x2))\n        reward = -dist_to_gap / 50.0\n    \n    # Penalty for falling (below gap level)\n    if agent['y'] < gap_y - 10:\n        reward = -10.0\nelse:\n    # No gap defined, just move toward goal\n    if env_state['goals']:\n        goal = env_state['goals'][0]\n        dist = math.sqrt((goal['x']-agent['x'])**2 + (goal['y']-agent['y'])**2)\n        reward = -dist / 100.0",
    "training_params": {
        "algo": "PPO",
        "total_timesteps": 100000,
        "learning_rate": 0.0003,
        "gamma": 0.99,
        "batch_size": 64,
        "n_envs": 8,
        "max_episode_steps": 300
    }
}